---
title: "Data_Analysis"
author: "Breanna Jones, Alex Johnson, Lily Foote"
date: "2024-04-08"
output: html_document
---

## Libraries Used

```{r libraries, message = FALSE, warning = FALSE}
#install.packages("NHANES")
#install.packages("RANN")

library(tidyverse)
library(caret) 
library(randomForest)
library(gbm)
library(ipred)
library(xgboost)
library(Metrics)
library(NHANES)
library(RANN)
```

## Cleaned Data

### Reading in Data

```{r reading}
olym <- read.csv(file = "dataset_olympics.csv")
region <- read.csv(file = "noc_region.csv")
```

### Cleaning the Data

Below we create our final dataset for use in analysis, `olym_new`.

```{r cleaning, message = FALSE}
# Region codes
olym$NOC <- gsub("SGP", "SIN", olym$NOC)

# Disciplines
olym_sport <- olym %>% 
  rename(Discipline = Sport) %>% 
  mutate(Sport = case_when(
    Discipline == "Swimming" | 
      Discipline == "Diving" |
      Discipline == "Water Polo" |
      Discipline == "Synchronized Swimming" ~ "Aquatics",
    Discipline == "Volleyball" |
      Discipline == "Beach Volleyball" ~ "Volleyball",
    Discipline == "Gymnastics" |
      Discipline == "Rhythmic Gymnastics" ~ "Gymnastics",
    Discipline == "Bobsleigh" |
      Discipline == "Skeleton" ~ "Bobsleigh",
    Discipline == "Speed Skating" |
      Discipline == "Short Track Speed Skating" |
      Discipline == "Figure Skating" ~ "Skating",
    Discipline == "Alpine Skiing" |
      Discipline == "Cross Country Skiing" |
      Discipline == "Ski Jumping" |
      Discipline == "Nordic Combined" |
      Discipline == "Freestyle Skiing" |
      Discipline == "Snowboarding" ~ "Skiing")) %>% 
  filter(Sport == "Skiing" | Sport == "Skating" | Sport == "Bobsleigh" | Sport == "Gymnastics" | Sport == "Volleyball" | Sport == "Aquatics") %>%
  filter(Year >= 1980) %>% 
  na.omit() %>% 
  mutate(is_medalist = ifelse((Medal == "Bronze" | Medal == "Silver" | Medal == "Gold"), "medalist", "nonmedalist"))

# Joining by Region
olym_reg <- left_join(olym_sport, region, by = join_by(NOC == noc_region))

# Omitting NA values
olym_reg <- na.omit(olym_reg)

# Replacing blank values for `Medal` with "none"
olym_reg[olym_reg == ""] <- "none" 

# Reordering columns, making variable names uniform, changing variable types
olym_clean <- olym_reg %>%
  rename(Region = reg) %>%
  mutate(Sex = as.factor(Sex)) %>% 
  mutate(is_medalist = as.factor(is_medalist)) %>% 
  mutate(Medal = factor(Medal, levels = c("none", "Bronze", "Silver", "Gold"))) %>% 
  mutate(Season = as.factor(Season)) %>% 
  select(ID, Name, Sex, Age, Height, Weight, Region, NOC, Year, Season, City, Sport, Discipline, Event, is_medalist, Medal) 

# Percent of athletes that are medalists...
sum(olym_clean$is_medalist == "medalist") / sum(olym_clean$is_medalist == "nonmedalist")

#This is no good! We need a more equal proportion of medalists to nonmedalists.

# Separating medalists and nonmedalists:
medalists <- olym_clean %>% 
  filter(is_medalist == "medalist")

nonmedalists <- olym_clean %>% 
  filter(is_medalist == "nonmedalist")

# Creating an index of nonmedalists: random sample of half the observations
nonmedalist_index <- sample(nrow(nonmedalists), size = 0.5*(nrow(nonmedalists)))

# Joining the randomly sampled half of the nonmedalists with the medalists to create a new, balanced data set
olym_new <- full_join(nonmedalists[nonmedalist_index, ], medalists)

# Proportion is better!
sum(olym_new$is_medalist == "medalist") / sum(olym_new$is_medalist == "nonmedalist")
```

## Partitioning the Data

```{r partition}
set.seed(4)

trainIndex <- createDataPartition(y = olym_new$is_medalist,
                                  p = 0.8,
                                  list = FALSE,
                                  times = 1)

train <- olym_new[trainIndex, ]
test <- olym_new[-trainIndex, ]

nrow(train) / nrow(olym_new)

# Transforming all strings to factors in train and test
train <- as.data.frame(unclass(train),                
                       stringsAsFactors = TRUE)
test <- as.data.frame(unclass(test),                  
                       stringsAsFactors = TRUE)

#Creating copies: train2 and test2
train2 <- train
test2 <- test

# Transforming predictor to binary values in train2 and test2
train2$is_medalist <- as.factor(
  ifelse(train2$is_medalist == "medalist", 1, 0))
test2$is_medalist <- as.factor(
  ifelse(test2$is_medalist == "medalist", 1, 0))
```

## Cross-Validation

```{r CV}
set.seed(4)

CVcontrol <- trainControl(
  method = "repeatedcv",
  number = 10,
  repeats = 5,
  savePredictions ="final",
  summaryFunction = twoClassSummary,
  classProbs = TRUE)
```


## Models

### Basic Generalized Linear Model (`glm`)

```{r lm, warning = FALSE}
set.seed(4)

#training model
lm_mod <- train(
  is_medalist ~ Sex + Age + Height + Weight + Year + Season + Sport + Discipline,
  train,
  method = "glm",
  trControl = CVcontrol)

#running predictions
lm_preds <- predict(object = lm_mod, newdata = test, type = "raw")

#number of predicted medalists:
sum(lm_preds == "medalist")

#creating a binary version of lm_preds: lm_preds2
lm_preds2 <- lm_preds
lm_preds2 <- as.factor(
  ifelse(lm_preds2 == "medalist", 1, 0))

#finding AUC using lm_preds2 and test2
auc(test2$is_medalist, lm_preds2)

#accuracy(test$is_medalist, lm_preds)
```

### Logistic Model

```{r logit, warning = FALSE}
set.seed(4)

#training model (binary)
logit_mod <- glm(
  is_medalist ~ Sex + Age + Height + Weight + Year + Season + Sport + Discipline,
  train2,
  family = "binomial")

# questionable logit code:
#logit_mod <- train(
#  is_medalist ~ Sex + Age + Height + Weight + Year + Season + Sport + Discipline,
#  train,
#  method = "glm",
#  family = binomial(),
#  trControl = CVcontrol)

#running probabilities (binary)
logit_probs <- predict(object = logit_mod, newdata = test2, type = "response")

#finding predictions from probabilities (binary)
logit_preds <- as.factor(
  ifelse(logit_probs >= 0.5, 1, 0))

#number of predicted medalists (binary)
sum(logit_preds == 1)

#finding AUC using logit_preds and test2
auc(test2$is_medalist, logit_preds)
```

### Lasso Model

```{r lasso}
set.seed(4)

#creating lasso grid with alpha = 1 to find best lambda value
lassoGrid = expand.grid(alpha = 1,
                        lambda = seq(0.001, 0.1, length.out = 10))

#training model
Lasso_mod <- train(
  is_medalist ~ Sex + Age + Height + Weight + Year + Season + Sport + Discipline,
  data = train,
  method = "glmnet",
  family = "binomial",
  trControl = CVcontrol,
  tuneGrid = lassoGrid)

#viewing model output
Lasso_mod

#running predictions
lasso_preds <- predict(object = Lasso_mod, newdata = test, type = "raw")

#number of predicted medalists:
sum(lasso_preds == "medalist")

#creating a binary version of lasso_preds: lasso_preds2
lasso_preds2 <- lasso_preds
lasso_preds2 <- as.factor(
  ifelse(lasso_preds2 == "medalist", 1, 0))

#finding AUC using lasso_preds2 and test2
auc(test2$is_medalist, lasso_preds2)

#accuracy(test$is_medalist, lasso_preds)
```

### Ridge Regression Model

```{r ridge, warning = FALSE}
set.seed(4)

#creating ridge grid with alpha = 0 to find best lambda value
ridgeGrid = expand.grid(alpha = 0,
                        lambda = seq(0.001, 0.1, length.out = 10))

#training model
Ridge_mod <- train(
  is_medalist ~ Sex + Age + Height + Weight + Year + Season + Sport + Discipline,
  data = train,
  method = "glmnet",
  family = "binomial",
  trControl = CVcontrol,
  tuneGrid = ridgeGrid)

#viewing model output
Ridge_mod

#running predictions
ridge_preds <- predict(object = Ridge_mod, newdata = test, type = "raw")

#number of predicted medalists:
sum(ridge_preds == "medalist")

#creating a binary version of ridge_preds: ridge_preds2
ridge_preds2 <- ridge_preds
ridge_preds2 <- as.factor(
  ifelse(ridge_preds2 == "medalist", 1, 0))

#finding AUC using ridge_preds2 and test2
auc(test2$is_medalist, ridge_preds2)

#accuracy(test$is_medalist, ridge_preds)
```

### Random Forest

```{r, random forest}
set.seed(4)

train_rf <- train
test_rf <- test

train_rf$is_medalist <- ifelse(train_rf$is_medalist == "medalist", 1, 0)
test_rf$is_medalist <- ifelse(test_rf$is_medalist == "medalist", 1, 0)

rf_model <- randomForest(as.factor(is_medalist) ~ Sex + Age + Height + Weight + Year + Season + Sport + Discipline, data = train_rf, importance = TRUE)
rf_model
varImpPlot(rf_model,main = NULL)

class_prediction <- predict(object = rf_model,
                             newdata = test_rf,
                             type = "class")
rf_preds <- predict(object = rf_model,
                             newdata = test_rf,
                             type = "prob")

cm <- confusionMatrix(data = class_prediction,
                reference = as.factor(test_rf$is_medalist))

#Test set accuracy
cm$overall[1]

#OOB accuracy
error <- rf_model$err.rate
oob_error <- error[nrow(error), "OOB"]
oob_error
1 - oob_error

#AUC
auc(actual = test_rf$is_medalist, predicted = class_prediction)
```

### Boosted Tree Model (GBM)

- Gradient-boosted model

```{r gbm}
set.seed(5)

#creating copies of train and test for gbm
train_gbm <- train
test_gbm <- test

#changing train set for gbm with response converted to 0 and 1 values
train_gbm$is_medalist <- ifelse(train_gbm$is_medalist == "medalist", 1, 0)

test_gbm$is_medalist <- ifelse(test$is_medalist == "medalist", 1, 0)

#making sure all string values in new train and test are factors
train_gbm <- as.data.frame(unclass(train_gbm),                
                       stringsAsFactors = TRUE)
test_gbm <- as.data.frame(unclass(test_gbm),                  
                       stringsAsFactors = TRUE)

#training gbm model on train_gbm
gbm_model <- gbm(formula = is_medalist ~ .-Name -Region -NOC -City -Event -ID -Medal, 
                    distribution = "bernoulli", 
                    data = train_gbm,
                    n.trees = 5000,
                    cv.folds = 10)

#finding optimal n.trees value
gbm_optimal_trees <- gbm.perf(object = gbm_model,
                          method = "OOB",
                          oobag.curve = TRUE)
gbm_optimal_trees2 <- gbm.perf(object = gbm_model, 
                         method = "cv")

gbm_optimal_trees[1]
gbm_optimal_trees2[1]

#viewing model
gbm_model
summary(gbm_model)
```

#### Testing Predictions

```{r gbm-2}
test_gbm$is_medalist <- ifelse(test$is_medalist == "medalist", 1, 0)

gbm_preds <- predict(object = gbm_model, 
                  newdata = test_gbm,
                  n.trees = 10000)
#returns log-scaled values

gbm_preds2 <- predict(object = gbm_model, 
                  newdata = test_gbm,
                  n.trees = 10000,
                  type = "response") #returns original-scaled values
```

##### Calculating Test AUC

```{r gbm-3}
auc(actual = test_gbm$is_medalist, predicted = gbm_preds)
auc(actual = test_gbm$is_medalist, predicted = gbm_preds2)
```


